# **CLCNet: Rethinking of Ensemble Modeling with Classification Confidence Network**

This repository is the official implementation of [CLCNet](https://arxiv.org/abs/2030.12345). 

### **Architecture Diagram**
![Architecture](https://github.com/yaoching0/CLCNet/blob/main/images/fig1-1.jpg)


## **1. Requirements**

To install requirements:

```setup
pip install -r requirements.txt
```
## **2. Download ImageNet-1k validation set**

We divided ImageNet-1k val set into five equal parts for subsequent cross validation : [Google Drive](https://drive.google.com/file/d/1dnFNH0LZfs_UpzDms5FBznupKph38pBV/view?usp=sharing)

Please unzip it and place it in the following path:

```ImageNet
[root of repository]\data\imagenet_splits_5\...
```

## **3. Generate dataset for training CLCNet**
You can directly download the dataset already generated by EfficientNet-B4 (used in the paper) for CLCNet training: [Google Drive](https://drive.google.com/file/d/1RGDtI0Y78muoAK6H7CcD2S1qElfDlplN/view?usp=sharing), and put it in `[root of repository]\data\(named)effb4_output_ds_for_CLCNet.csv`.


### (optional) Or you can also generate by your own:
By default, we use [timm](https://github.com/rwightman/pytorch-image-models) pre-trained model (automatic download) to classify ImageNet-1k val and save the results for subsequent CLCNet training, and the classification results will be saved in the root directory of the repository:

```generate CLCNet dataset
python generate_data_for_CLCNet.py --model tf_efficientnet_b4
```


We support all classification models in the [timm](https://github.com/rwightman/pytorch-image-models) (see [model list](https://github.com/rwightman/pytorch-image-models/blob/master/results/results-imagenet.csv)), and you can also use your own weights trained with timm and generate training data for CLCNet on your own dataset.


```generate customized CLCNet dataset
python generate_data_for_CLCNet.py --data-path <path_of_custom_data> --model <timm_model_name> --model-weight <path_of_model_weight> --num_classes <num_cls> --output <path_of_output_result>
```


### The generated dataset will be a csv file in the following format:

```dataset format
[filename][sorted n-dim(ImageNet:n=1000) classifcation probilities][label (1 or 0)] 
[filename][sorted n-dim(ImageNet:n=1000) classifcation probilities][label (1 or 0)] 
...
```

## **4. ImageNet-1k cross validation**

### Training
The path `[root of repository]\weights` already contains the CLCNet weights we trained as follow:

#### (optional) Training process
First, we use the dataset generated in the previous step to train CLCNet. We divide ImageNet-1k val into 40,000 and 10,000 parts each time, we will only use the 40,000 parts to train and validate CLCNet, repeat five times to make the part of 10,000 dataset cover the entire ImageNet, and generate five CLCNet weights. The weights will be saved in ```[root of repository]\weights``` by default:

```train
python train(imagenet-5-fold-cv).py --imagenet-split <path_of_step2_downloaded_ImageNet> --cls-output <path_of_previous_generated_csv>
```

Of course, you can also specify training hyperparameters:

```train
python train(imagenet-5-fold-cv).py --max-epochs 200 --batch-size 256 --imagenet-split <path_of_step2_downloaded_ImageNet> --cls-output <path_of_previous_generated_csv>
```

For more details, please see the parameter description in the py file.

### Evaluation

To evaluate cascade structure system on ImageNet-1k val, run:


```eval
python eval(imagenet-5-fold-cv).py --threshold 0.5 --shallow-model tf_efficientnet_b4 --shallow-model-FLOPs 4.2 --deep-model tf_efficientnet_b7 --deep-model-FLOPs 37
```

The system will automatically use the five CLCNet weights (`[root of repository]\weights`) we trained in the previous step and the weights pre-trained by timm (automatic download, we support all models in timm, see [model list](https://github.com/rwightman/pytorch-image-models/blob/master/results/results-imagenet.csv)) on ImageNet (`[root of repository]\data\imagenet_splits_5\...`) to calculate the accuracy and FLOPs under the _threshold_, and save them as a csv file in `[root of repository]\performance-result.csv`.

You can also use `--threshold-searching True` to automatically calculate the accuracy and FLOPs under different thresholds between [0.2, 1].


#### (Important) Single model accuracy
To compare with single model (like EfficientNet-b4) in the system, the values (accuracy) in the [model list](https://github.com/rwightman/pytorch-image-models/blob/master/results/results-imagenet.csv) will be different under different hardware environments, please test separately.


You can make the model to be tested as the shallow model in the system, and set the threshold to a very small value. So the deep model will not be used, and the accuracy of the system is the accuracy of the shallow model:

```eval
python eval(imagenet-5-fold-cv).py --threshold -999 --shallow-model tf_efficientnet_b4
```

## 5. (optional) Training and evaluation with custom data

You can use the dataset obtained in step 3 to train CLCNet without cross validation (so you will only get one weight, and saved in the `[root of repository]\weights`):

```train
python train(custom-data).py --cls-output <path_of_previous_generated_csv>
```


Use the above trained CLCNet weight to test performance of cascade structure system on custom dataset, and the shallow and deep models can be replaced by any timm [models](https://github.com/rwightman/pytorch-image-models/blob/master/results/results-imagenet.csv) trained by custom dataset:

```eval
python eval(custom-data).py --custom-data <custom_dataset_for_inference> --threshold 0.5 --num_classes <any_num_cls> --shallow-model tf_efficientnet_b4 --shallow-model-FLOPs 4.2 --shallow-model-weight <path_of_model_weight> --deep-model tf_efficientnet_b7 ---deep-model-FLOPs 37 --deep-model-weight <path_of_model_weight> 
```

The system will infer each image in `<custom_dataset_for_inference>` and save the classification results in `[root of repository]\custom-data-result.csv`.


## **6.Results**

Use the variant of EfficientNet as shallow model and deep model of cascade structure system, and compare with the original EfficientNet on ImageNet-1k:


| Model name         | Top 1 Accuracy  |   Threshold    | FLOPs per image |
---|:--:|:--:|:--:|
| EfficientNet-B0    |     75.40%  |       --       |      0.39B      |
| EfficientNet-B1    |     77.64%  |       --       |      0.7B      |
| CLCNet (S:B0+D:B4)    |   **77.74%**   |       0.19      |    **0.74B**       |
| EfficientNet-B2    |     78.73%  |       --       |      1.0B      |
| CLCNet (S:B0+D:B4)    |   79.06%   |      0.27       |     **0.996B**       |
| CLCNet (S:B0+D:B4)    |    **78.71%**  |       0.25      |     0.933B       |
| EfficientNet-B3    |     80.52%  |       --       |      1.8B      |
| CLCNet (S:B0+D:B4)    |    81.19%  |       0.43      |    **1.77B**        |
| CLCNet (S:B0+D:B4)    |    **80.50%**  |     0.39        |    1.42B        |
| EfficientNet-B4    |     82.00%  |       --       |      4.2B      |
| CLCNet (S:B0+D:B4)    |   **82.02%**   |      0.05       |    **4.27B**       |
| EfficientNet-B5    |     82.72%  |       --       |      9.9B      |
| CLCNet (S:B0+D:B4)    |  83.59%   |      0.45       |     **9.94B**       |
| CLCNet (S:B0+D:B4)    |    **82.75%**  |      0.27       |    6.1B        |
| EfficientNet-B6    |     83.30%  |       --       |      19B      |
| CLCNet (S:B0+D:B4)    |   83.88%   |      0.83       |    **18.58B**        |
| CLCNet (S:B0+D:B4)    |    **83.42%**  |      0.39       |    8.95B        |
| EfficientNet-B7    |     83.80%  |       --       |      37B      |
| CLCNet (S:B0+D:B4)    |    **83.88%**  |     0.83        |   18.58B         |

> Bold indicates the value of the metric is close to EfficientNet variant, S and D stand for shallow model and deep model respectively, and we use CLCNet to denote the cascade structure system using CLCNet.
